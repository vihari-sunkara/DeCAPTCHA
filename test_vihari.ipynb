{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /home/vihari/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
      "100.0%\n",
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet101_coco-586e9e4e.pth\" to /home/vihari/.cache/torch/checkpoints/deeplabv3_resnet101_coco-586e9e4e.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "dlab = models.segmentation.deeplabv3_resnet101(pretrained=1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_segmap(image, source, nc=21):\n",
    "    foreground = cv2.imread(source)\n",
    " \n",
    "    # Change the color of foreground image to RGB\n",
    "    # and resize image to match shape of R-band in RGB output map\n",
    "    foreground = cv2.cvtColor(foreground, cv2.COLOR_BGR2RGB)\n",
    "    foreground = cv2.resize(foreground,(r.shape[1],r.shape[0]))\n",
    "\n",
    "    # Create a background array to hold white pixels\n",
    "    # with the same size as RGB output map\n",
    "    background = 255 * np.ones_like(rgb).astype(np.uint8)\n",
    "\n",
    "    # Convert uint8 to float\n",
    "    foreground = foreground.astype(float)\n",
    "    background = background.astype(float)\n",
    "\n",
    "    # Create a binary mask of the RGB output map using the threshold value 0\n",
    "    th, alpha = cv2.threshold(np.array(rgb),0,255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply a slight blur to the mask to soften edges\n",
    "    alpha = cv2.GaussianBlur(alpha, (7,7),0)\n",
    "\n",
    "    # Normalize the alpha mask to keep intensity between 0 and 1\n",
    "    alpha = alpha.astype(float)/255\n",
    "\n",
    "    # Multiply the foreground with the alpha matte\n",
    "    foreground = cv2.multiply(alpha, foreground)\n",
    "\n",
    "    # Multiply the background with ( 1 - alpha )\n",
    "    background = cv2.multiply(1.0 - alpha, background)\n",
    "\n",
    "    # Add the masked foreground and background\n",
    "    outImage = cv2.add(foreground, background)\n",
    "\n",
    "    # Return a normalized output image for display\n",
    "    return outImage/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/build/opencv-L2vuMj/opencv-3.2.0+dfsg/modules/imgproc/src/color.cpp:9716: error: (-215) scn == 3 || scn == 4 in function cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-81eab3517c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode_segmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./images/bgremoval/redcar.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9fac8b21ff77>\u001b[0m in \u001b[0;36mdecode_segmap\u001b[0;34m(image, source, nc)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Change the color of foreground image to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# and resize image to match shape of R-band in RGB output map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mforeground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforeground\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mforeground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforeground\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/opencv-L2vuMj/opencv-3.2.0+dfsg/modules/imgproc/src/color.cpp:9716: error: (-215) scn == 3 || scn == 4 in function cvtColor\n"
     ]
    }
   ],
   "source": [
    "decode_segmap(dlab, './images/bgremoval/redcar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('train/AISL.png',0)\n",
    "orig = img\n",
    "img = img[10:140, 10:570]\n",
    "\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "# rect = (50,50,450,350)\n",
    "rect = (5,5,550,250)\n",
    "# cv.grabCut(img,mask,rect,bgdModel,fgdModel,7,cv.GC_INIT_WITH_RECT)\n",
    "# mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "# img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "img = cv2.medianBlur(img, 7)\n",
    "# img = cv2.GaussianBlur(img,(7,7),0)\n",
    "th, img = cv2.threshold(img, 120, 250, cv2.THRESH_BINARY)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "img_dilation = cv2.dilate(img_erosion, kernel, iterations=2) \n",
    "cv.imshow('dilated',img_dilation)\n",
    "\n",
    "cv.imshow('orig',orig)\n",
    "\n",
    "\n",
    "# backSub = cv.createBackgroundSubtractorMOG2(history=1)\n",
    "# img_dilation = backSub.apply(img_dilation)\n",
    "# cv.imshow('mask',img_dilation)\n",
    "\n",
    "# img = cv.imread('AAA.png')\n",
    "\n",
    "cv.waitKey(0)\n",
    "# plt.imshow(img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread(\"AAA.png\")\n",
    "crop_img = img[30:140, 20:500]\n",
    "cv.imshow(\"cropped\", crop_img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7ceb853e2ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmasked_img_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdilation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_img_inv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to remove blackline noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result1.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "img = cv2.imread('AAA.png',0)\n",
    "\n",
    "#display image in window\n",
    "#cv2.imshow('image',img) #@param - windowname, image to be displayed\n",
    "\n",
    "horizontal_inv = cv2.bitwise_not(img)\n",
    "#perform bitwise_and to mask the lines with provided mask\n",
    "masked_img = cv2.bitwise_and(img, img, mask=horizontal_inv)\n",
    "#reverse the image back to normal\n",
    "masked_img_inv = cv2.bitwise_not(masked_img)\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilation = cv2.dilate(masked_img_inv,kernel,iterations = 3) # to remove blackline noise\n",
    "cv2.imwrite(\"result1.jpg\", dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh2 = cv2.threshold(dilation,254,255,cv2.THRESH_BINARY_INV) \n",
    "thresh2=cv2.bitwise_not(thresh2)\n",
    "# cv2.imshow(\"masked img\", masked_img_inv)\n",
    "cv2.imwrite(\"result2.jpg\", thresh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "\n",
    "def prepare_image(img):\n",
    "    \"\"\"Transform image to greyscale and blur it\"\"\"\n",
    "    img = img.filter(ImageFilter.SMOOTH_MORE)\n",
    "    img = img.filter(ImageFilter.SMOOTH_MORE)\n",
    "    if 'L' != img.mode:\n",
    "        img = img.convert('L')\n",
    "    return img\n",
    "\n",
    "def remove_noise(img, pass_factor):\n",
    "    for column in range(img.size[0]):\n",
    "        for line in range(img.size[1]):\n",
    "            value = remove_noise_by_pixel(img, column, line, pass_factor)\n",
    "            img.putpixel((column, line), value)\n",
    "    return img\n",
    "\n",
    "def remove_noise_by_pixel(img, column, line, pass_factor):\n",
    "    if img.getpixel((column, line)) < pass_factor:\n",
    "        return (0)\n",
    "    return (255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image = sys.argv[1]\n",
    "for f in os.listdir(\"train\"):\n",
    "    input_image = f\n",
    "    output_image = input_image\n",
    "    pass_factor = 140\n",
    "\n",
    "    img = Image.open('train/'+input_image)\n",
    "    img = prepare_image(img)\n",
    "    img = remove_noise(img, pass_factor)\n",
    "    \n",
    "    \n",
    "    img.save('train_out/'+output_image,'png')\n",
    "    kernel = np.ones((3,3), np.uint8) \n",
    "    img = cv2.imread('train_out/'+output_image,0)\n",
    "    img_dilation = cv2.dilate(img, kernel, iterations=1) \n",
    "    cv2.imwrite('train_out/'+output_image, img_dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = \"AHLD.png\"\n",
    "output_image = input_image\n",
    "pass_factor = 140\n",
    "\n",
    "img = Image.open(input_image)\n",
    "img = prepare_image(img)\n",
    "img = remove_noise(img, pass_factor)\n",
    "\n",
    "\n",
    "img.save('_out'+output_image,'png')\n",
    "kernel = np.ones((3,3), np.uint8) \n",
    "img = cv2.imread('_out'+output_image,0)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1) \n",
    "cv2.imwrite('_out'+output_image, img_dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fnmatch\n",
    "# import os\n",
    "\n",
    "# # print([f for f in os.listdir(\"train\") if fnmatch.fnmatch(f, '*.png')])\n",
    "# import fnmatch\n",
    "# import os\n",
    "\n",
    "# for f in os.listdir(\"train\"):\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_image(img):\n",
    "#     height, width = img.shape[:2]\n",
    "\n",
    "#     # Specify the color range of the lines you want to remove [lower, upper]\n",
    "#     lower = [0, 0, 0]\n",
    "#     upper = [100, 100, 100]\n",
    "#     lower = np.array(lower, dtype = \"uint8\")\n",
    "#     upper = np.array(upper, dtype = \"uint8\") \n",
    "\n",
    "#     # Create a mask of the lines\n",
    "#     mask = cv2.inRange(img, lower, upper)\n",
    "\n",
    "#     output = cv2.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "#     # As the original comment explains, dilate lines a bit because aliasing \n",
    "#     # may have filtered borders too much during masking \n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "#     dilation = cv2.dilate(output, kernel, iterations = 2)\n",
    "\n",
    "#     # Conver the mask to gray scale\n",
    "#     gray = cv2.cvtColor(dilation, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Reference: https://docs.opencv.org/trunk/df/d3d/tutorial_py_inpainting.html\n",
    "#     # Apply the mask created above on the image\n",
    "#     dst = cv2.inpaint(img,gray,5,cv2.INPAINT_NS)\n",
    "\n",
    "\n",
    "#     # Post mask application, there will be inconsistency/gaps/separation of individual \n",
    "#     # digits/alphabets. So we dilate (puff up the white blobs) so that each individual \n",
    "#     # digit gets properly connected and considered as one blob (which can be further used\n",
    "#     # to find contours)\n",
    "#     dilation = cv2.dilate(dst, kernel, iterations = 1)\n",
    "\n",
    "#     # Reference for blurring and bilateral filtering: \n",
    "#     # https://docs.opencv.org/3.1.0/d4/d13/tutorial_py_filtering.html\n",
    "#     blur = cv2.GaussianBlur(dilation,(5,5),0)\n",
    "#     bilateral = cv2.bilateralFilter(blur,5,75,75)\n",
    "#     gray = cv2.cvtColor(bilateral, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # If pixel value is greater than a threshold value, it is assigned one value (may be white), \n",
    "#     # else it is assigned another value (may be black)\n",
    "#     # Reference: https://docs.opencv.org/3.4.0/d7/d4d/tutorial_py_thresholding.html\n",
    "#     thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#     return thresh\n",
    "\n",
    "# # Read the image using cv2.imread() and pass it to the clean_image function\n",
    "\n",
    "# # if __name__ == '__main__':\n",
    "# #     b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = cv2.imread(\"train_out/BCQ.png\")\n",
    "# img = clean_image(img)\n",
    "# cv2.imshow(\"Final Output\", img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#Read gray image\n",
    "img = cv2.imread(\"AAA.png\",0)\n",
    "\n",
    "#Create default parametrization LSD\n",
    "lsd = cv2.createLineSegmentDetector(0)\n",
    "\n",
    "#Detect lines in the image\n",
    "lines = lsd.detect(img)[0] #Position 0 of the returned tuple are the detected lines\n",
    "\n",
    "#Draw the detected lines\n",
    "drawn_img = lsd.drawSegments(img,lines)\n",
    "\n",
    "#Save the image with the detected lines\n",
    "cv2.imwrite('lsdsaved.png', drawn_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for element in lines:\n",
    "\n",
    "    #If the length of the line is more than 50, then draw a white line on it\n",
    "    if (abs(int(element[0][0]) - int(element[0][2])) > 50 or abs(int(element[0][1]) - int(element[0][3])) > 50): \n",
    "\n",
    "    #Draw the white line\n",
    "        cv2.line(img, (int(element[0][0]), int(element[0][1])), (int(element[0][2]), int(element[0][3])), (255, 255, 255), 12)\n",
    "\n",
    "#Save the final image\n",
    "cv2.imwrite('removedzz.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "  \n",
    "# Reading the input image \n",
    "img = cv2.imread('train/BSPC.png', 0) \n",
    "  \n",
    "# Taking a matrix of size 5 as the kernel \n",
    "kernel = np.ones((2,2), np.uint8) \n",
    "  \n",
    "# The first parameter is the original image, \n",
    "# kernel is the matrix with which image is  \n",
    "# convolved and third parameter is the number  \n",
    "# of iterations, which will determine how much  \n",
    "# you want to erode/dilate a given image.  \n",
    "\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1) \n",
    "img_erosion = cv2.erode(img_dilation, kernel, iterations=1) \n",
    "  \n",
    "cv2.imshow('Input', img) \n",
    "\n",
    "cv2.imshow('Dilation', img_dilation) \n",
    "cv2.imshow('Erosion', img_erosion) \n",
    "# cv2.imwrite('removedzz.png', img_dilation)\n",
    "  \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "def img_train_test_split(img_source_dir, train_size):\n",
    "    \"\"\"\n",
    "    Randomly splits images over a train and validation folder, while preserving the folder structure\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img_source_dir : string\n",
    "        Path to the folder with the images to be split. Can be absolute or relative path   \n",
    "        \n",
    "    train_size : float\n",
    "        Proportion of the original images that need to be copied in the subdirectory in the train folder\n",
    "    \"\"\"    \n",
    "    if not (isinstance(img_source_dir, str)):\n",
    "        raise AttributeError('img_source_dir must be a string')\n",
    "        \n",
    "    if not os.path.exists(img_source_dir):\n",
    "        raise OSError('img_source_dir does not exist')\n",
    "        \n",
    "    if not (isinstance(train_size, float)):\n",
    "        raise AttributeError('train_size must be a float')\n",
    "        \n",
    "    # Set up empty folder structure if not exists\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    else:\n",
    "        if not os.path.exists('data/train'):\n",
    "            os.makedirs('data/train')\n",
    "        if not os.path.exists('data/validation'):\n",
    "            os.makedirs('data/validation')\n",
    "            \n",
    "    # Get the subdirectories in the main image folder\n",
    "#     subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]\n",
    "\n",
    "#     for subdir in subdirs:\n",
    "#         subdir_fullpath = os.path.join(img_source_dir, subdir)\n",
    "#         if len(os.listdir(subdir_fullpath)) == 0:\n",
    "#             print(subdir_fullpath + ' is empty')\n",
    "#             break\n",
    "\n",
    "#         train_subdir = os.path.join('data/train', subdir)\n",
    "#         validation_subdir = os.path.join('data/validation', subdir)\n",
    "\n",
    "#         # Create subdirectories in train and validation folders\n",
    "#         if not os.path.exists(train_subdir):\n",
    "#             os.makedirs(train_subdir)\n",
    "\n",
    "#         if not os.path.exists(validation_subdir):\n",
    "#             os.makedirs(validation_subdir)\n",
    "\n",
    "    train_counter = 0\n",
    "    validation_counter = 0\n",
    "    subdir_fullpath = img_source_dir\n",
    "    train_subdir = \"data/train\"\n",
    "    validation_subdir = \"data/validation\"\n",
    "    # Randomly assign an image to train or validation folder\n",
    "    for filename in os.listdir(subdir_fullpath):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            fileparts = filename.split('.')\n",
    "\n",
    "            if random.uniform(0, 1) <= train_size:\n",
    "                copyfile(os.path.join(subdir_fullpath, filename), os.path.join(train_subdir, fileparts[0] + '.' + fileparts[1]))\n",
    "                train_counter += 1\n",
    "            else:\n",
    "                copyfile(os.path.join(subdir_fullpath, filename), os.path.join(validation_subdir, fileparts[0] + '.' + fileparts[1]))\n",
    "                validation_counter += 1\n",
    "                    \n",
    "#         print('Copied ' + str(train_counter) + ' images to data/train/' + subdir)\n",
    "#         print('Copied ' + str(validation_counter) + ' images to data/validation/' + subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_test_split(\"train_out\", 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "\n",
    "kernel = np.ones((4,4), np.uint8) \n",
    "img = cv.imread('train/AAA.png')\n",
    "orig = img\n",
    "img = img[20:140, 10:500]\n",
    "# img = cv2.resize(img, None, fx=10, fy=10, interpolation=cv2.INTER_LINEAR)\n",
    "img = cv2.medianBlur(img, 7)\n",
    "# img = cv2.GaussianBlur(img,(7,7),0)\n",
    "th, img = cv2.threshold(img, 120, 250, cv2.THRESH_BINARY)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "img_dilation = cv2.dilate(img_erosion, kernel, iterations=1) \n",
    "cv.imshow('dilated',img_dilation)\n",
    "cv.waitKey(0)\n",
    "# img_dilation = cv2.bitwise_not(img_dilation)\n",
    "# img_dilation = cv2.cvtColor(img_dilation, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_dilation\n",
    "img = cv2.medianBlur(img, 5)\n",
    "# img = cv2.GaussianBlur(img,(7,7),0)\n",
    "th, img = cv2.threshold(img, 115, 250, cv2.THRESH_BINARY)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1) \n",
    "img_dilation1 = cv2.dilate(img_erosion, kernel, iterations=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Dilation1', img_dilation)\n",
    "cv2.imshow('Dilation2', img_dilation1) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SARS W'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "text = pytesseract.image_to_string(Image.open('BRSW.png'))  # We'll use Pillow's Image class to open the image and pytesseract to detect the string in the image\n",
    "text  # Then we will print the text in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "  \n",
    "# Image operation using thresholding \n",
    "img = cv2.imread('train/AAA.png') \n",
    "  \n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "ret, thresh = cv2.threshold(gray, 0, 255, \n",
    "                            cv2.THRESH_BINARY_INV +\n",
    "                            cv2.THRESH_OTSU) \n",
    "cv2.imshow('image', thresh) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.ones((4, 4), np.uint8) \n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, \n",
    "                            kernel, iterations = 2) \n",
    "  \n",
    "# Background area using Dialation \n",
    "# bg = cv2.dilate(closing, kernel, iterations = 2) \n",
    "# bg = cv2.erode(closing, kernel, iterations = 2)\n",
    "bg = cv2.dilate(closing, kernel, iterations = 2)\n",
    "# Finding foreground area \n",
    "dist_transform = cv2.distanceTransform(closing, cv2.DIST_L2, 0) \n",
    "ret, fg = cv2.threshold(dist_transform, 0.02\n",
    "                        * dist_transform.max(), 255, 0) \n",
    "  \n",
    "cv2.imshow('image', bg) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'createBackgroundSubtractorCNT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-28d1ceb9d853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# backSub = cv.createBackgroundSubtractorMOG2()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbackSub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateBackgroundSubtractorCNT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# capture = cv.VideoCapture(cv.samples.findFileOrKeep(args.input))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_out/AWS.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'createBackgroundSubtractorCNT'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# backSub = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "backSub = cv.createBackgroundSubtractorCNT()\n",
    "# capture = cv.VideoCapture(cv.samples.findFileOrKeep(args.input))\n",
    "img = cv.imread('train_out/AWS.png') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fgMask = backSub.apply(img)\n",
    "\n",
    "\n",
    "# cv.rectangle(img, (10, 2), (100,20), (255,255,255), -1)\n",
    "# cv.putText(img, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "#            cv.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "\n",
    "\n",
    "cv.imshow('Frame', img)\n",
    "cv.imshow('FG Mask', fgMask)\n",
    "\n",
    "cv.waitKey(0)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=600x150 at 0x7F249C0F4630>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# python chop.py [chop-factor] [in-file] [out-file]\n",
    "\n",
    "chop = 1\n",
    "image = Image.open('AISL.png').convert('1')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "<PIL.Image.Image image mode=L size=600x150 at 0x7F249C0BA438>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=600x150 at 0x7F249C0BA438>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# python chop.py [chop-factor] [in-file] [out-file]\n",
    "\n",
    "chop = 10\n",
    "image = PIL.Image.open('train/BDFP.png').convert('L')\n",
    "img = image.load()\n",
    "bg=img[2, 2]\n",
    "print(bg)\n",
    "\n",
    "\n",
    "print(image)\n",
    "width, height = image.size\n",
    "data = image.load()\n",
    "\n",
    "# Iterate through the rows.\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "\n",
    "        # Make sure we're on a dark pixel.\n",
    "        if data[x, y] > 128:\n",
    "            continue\n",
    "\n",
    "        # Keep a total of non-white contiguous pixels.\n",
    "        total = 0\n",
    "\n",
    "        # Check a sequence ranging from x to image.width.\n",
    "        for c in range(x, width):\n",
    "\n",
    "            # If the pixel is dark, add it to the total.\n",
    "            if data[c, y] < 128:\n",
    "                total += 1\n",
    "\n",
    "            # If the pixel is light, stop the sequence.\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # If the total is less than the chop, replace everything with white.\n",
    "        if total <= chop:\n",
    "            for c in range(total):\n",
    "                data[x + c, y] = bg\n",
    "\n",
    "        # Skip this sequence we just altered.\n",
    "        x += total\n",
    "\n",
    "\n",
    "# Iterate through the columns.\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "\n",
    "        # Make sure we're on a dark pixel.\n",
    "        if data[x, y] > 128:\n",
    "            continue\n",
    "\n",
    "        # Keep a total of non-white contiguous pixels.\n",
    "        total = 0\n",
    "\n",
    "        # Check a sequence ranging from y to image.height.\n",
    "        for c in range(y, height):\n",
    "\n",
    "            # If the pixel is dark, add it to the total.\n",
    "            if data[x, c] < 128:\n",
    "                total += 1\n",
    "\n",
    "            # If the pixel is light, stop the sequence.\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # If the total is less than the chop, replace everything with white.\n",
    "        if total <= chop:\n",
    "            for c in range(total):\n",
    "                data[x, y + c] = bg\n",
    "\n",
    "        # Skip this sequence we just altered.\n",
    "        y += total\n",
    "\n",
    "# image.save('AISL_gray.png')\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread('AISL_gray.png',0)\n",
    "im_color = cv2.applyColorMap(img, cv2.COLORMAP_OCEAN)\n",
    "cv2.imshow('Dilation0', im_color) \n",
    "# clr_img = cv.imread('AISL.png')\n",
    "img = cv2.medianBlur(img, 9)\n",
    "# img = cv2.GaussianBlur(img,(7,7),0)\n",
    "# th, img = cv2.threshold(img, 100, 10, cv2.THRESH_BINARY)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=2) \n",
    "# img_dilation = cv2.dilate(img_erosion, kernel, iterations=1) \n",
    "# img = cv2.cvtColor(img,clr_img,cv2.COLOR_GRAY2BGR)\n",
    "neg = cv2.bitwise_not(img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "im_color = cv2.applyColorMap(img, cv2.COLORMAP_OCEAN)\n",
    "# im_color1 = cv2.applyColorMap(im_color, cv2.COLOR_BGR2GRAY)\n",
    "# im_color1 = cv2.bitwise_not(im_color)\n",
    "cv2.imshow('DilationBlue', im_color) \n",
    "# im_color1 = cv2.cvtColor(im_color, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow('DilationNeg', im_color1) \n",
    "# cv2.imshow('Dilation4', neg) \n",
    "cv2.imwrite('train_out/BDFP.png',im_color)\n",
    "cv2.waitKey(0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = 1\n",
    "# beta = 1\n",
    "\n",
    "# new_image = np.zeros(img.shape)\n",
    "# for y in range(img.shape[0]):\n",
    "#     for x in range(img.shape[1]):\n",
    "#         new_image[y,x] = np.clip(alpha*img[y,x] + beta, 0, 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Dilation4', new_image) \n",
    "# cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2 as cv\n",
    "for f in os.listdir(\"train\"):\n",
    "    input_image = f\n",
    "    output_image = input_image\n",
    "    chop = 10\n",
    "    image = Image.open('train/'+input_image).convert('L')\n",
    "    img = image.load()\n",
    "    bg=img[2, 2]\n",
    "#     print(bg)\n",
    "\n",
    "#     output_image = 'AAE.png'\n",
    "#     print(image)\n",
    "    width, height = image.size\n",
    "    data = image.load()\n",
    "    max=255\n",
    "    # Iterate through the rows.\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "\n",
    "            # Make sure we're on a dark pixel.\n",
    "            if data[x, y] > 128:\n",
    "                continue\n",
    "            else:\n",
    "                if data[x, y]< max :\n",
    "                    max = data[x,y]\n",
    "            # Keep a total of non-white contiguous pixels.\n",
    "            total = 0\n",
    "\n",
    "            # Check a sequence ranging from x to image.width.\n",
    "            for c in range(x, width):\n",
    "\n",
    "                # If the pixel is dark, add it to the total.\n",
    "                if data[c, y] < 128:\n",
    "                    total += 1\n",
    "\n",
    "                # If the pixel is light, stop the sequence.\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # If the total is less than the chop, replace everything with white.\n",
    "            if total <= chop:\n",
    "                for c in range(total):\n",
    "                    data[x + c, y] = bg\n",
    "\n",
    "            # Skip this sequence we just altered.\n",
    "            x += total\n",
    "\n",
    "\n",
    "    # Iterate through the columns.\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "\n",
    "            # Make sure we're on a dark pixel.\n",
    "            if data[x, y] > 128:\n",
    "                continue\n",
    "\n",
    "            # Keep a total of non-white contiguous pixels.\n",
    "            total = 0\n",
    "\n",
    "            # Check a sequence ranging from y to image.height.\n",
    "            for c in range(y, height):\n",
    "\n",
    "                # If the pixel is dark, add it to the total.\n",
    "                if data[x, c] < 128:\n",
    "                    total += 1\n",
    "\n",
    "                # If the pixel is light, stop the sequence.\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # If the total is less than the chop, replace everything with white.\n",
    "            if total <= chop:\n",
    "                for c in range(total):\n",
    "                    data[x, y + c] = bg\n",
    "\n",
    "            # Skip this sequence we just altered.\n",
    "            y += total\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            if data[x, y] == bg:\n",
    "                data[x, y] = 255\n",
    "            else:\n",
    "                data[x, y] = 0\n",
    "            # Make sure we're on a dark pixel.\n",
    "    # image = data        \n",
    "    image.save('train_out/'+output_image)\n",
    "    img = cv.imread('train_out/'+output_image,0)\n",
    "    im_color = cv.applyColorMap(img, cv.COLORMAP_WINTER)\n",
    "#     cv.imshow('Dilation0', im_color) \n",
    "    # clr_img = cv.imread('AISL.png')\n",
    "    img = cv.medianBlur(img, 11)\n",
    "#     kernel = np.ones((4,4), np.uint8) \n",
    "    # img = cv2.GaussianBlur(img,(7,7),0)\n",
    "    # th, img = cv2.threshold(img, 100, 10, cv2.THRESH_BINARY)\n",
    "    # img_erosion = cv.erode(img, kernel, iterations=1) \n",
    "    # img_dilation = cv2.dilate(img_erosion, kernel, iterations=1) \n",
    "    # img = cv2.cvtColor(img,clr_img,cv2.COLOR_GRAY2BGR)\n",
    "    #     neg = cv2.bitwise_not(img)\n",
    "    #     cv2.imshow('Erosion', img_erosion)\n",
    "    im_color = cv.applyColorMap(img, cv.COLORMAP_WINTER)\n",
    "    # im_color1 = cv2.applyColorMap(im_color, cv2.COLOR_BGR2GRAY)\n",
    "    # im_color1 = cv2.bitwise_not(im_color)\n",
    "    #     cv2.imshow('DilationBlue', im_color) \n",
    "    # im_color1 = cv2.cvtColor(im_color, cv2.COLOR_BGR2GRAY)\n",
    "#     cv.imshow('DilationNeg', im_color) \n",
    "    # cv2.imshow('Dilation4', neg) \n",
    "    cv.imwrite('train_out/'+output_image,im_color)\n",
    "#     cv.waitKey(0) \n",
    "#     alpha = 0.9999999 # Contrast control (1.0-3.0)\n",
    "#     beta = 0 # Brightness control (0-100)\n",
    "\n",
    "#     adjusted = cv.convertScaleAbs(im_color, alpha=alpha, beta=beta)\n",
    "#     cv.imshow('adj', adjusted)\n",
    "\n",
    "#     neg = cv.cvtColor(adjusted,cv.COLOR_BGR2GRAY)\n",
    "#     cv.imshow('neg', neg) \n",
    "#     neg = cv.bitwise_not(neg)\n",
    "#     cv.imshow('not', neg) \n",
    "#     # cv.imwrite('train_out/'+output_image,im_color)\n",
    "#     cv.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
